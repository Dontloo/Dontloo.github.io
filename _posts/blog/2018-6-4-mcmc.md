---
layout: post
title: "Markov Chains ;]"
modified: 2018-06-14
categories: blog
excerpt:
tags: []
date: 2018-06-14
---

## Markov Chains

By Markov chains in this blog we refer to discrete-time homogeneous Markov chains.

**Discrete-time Markov chains** 
A discrete-time Markov chain is a sequence of random variables \\(\{X_1, X_2, X_3, ...\}\\) with the Markov property, namely that the probability of moving to the next state depends only on the present state and not on the previous states
\\[P(X_{n+1}|X_n,â€¦,X1) = P(X_{n+1}|X_n)\\]

**Homogeneous chains**
A homogeneous Markov chain is one that does not evolve in time, that is, its transition probabilities are independent of the time step \\(n\\)
\\[P(X_{n+1}|X_n) \text{is same} \forall n \leq 0 \\]


mcmc convergence https://www.youtube.com/watch?v=D8DZjLPlWd0&index=2&list=PLaNkJORnlhZmfwQITRbxXCzot3PSXlMYb
covergence time related to differential equations, adding a constant does not change eigenvectors (pagerank) https://www.youtube.com/watch?v=DzqE7tj7eIM
how to find eigenvalues and eigenvectors https://www.youtube.com/watch?v=lXNXrLcoerU
Stationary distributions, Irreducibility, and Aperiodicity https://www.youtube.com/watch?v=tByUQbJdt14  https://www.youtube.com/watch?v=Pce7KKeUf5w https://www.youtube.com/watch?v=daY4lgEyEPc
